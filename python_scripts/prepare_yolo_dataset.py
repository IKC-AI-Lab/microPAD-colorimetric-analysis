"""
Prepare YOLO dataset configuration and train/val splits for microPAD auto-detection.

This script restructures the augmented dataset for YOLO training:
1. Moves images from augmented_1_dataset/[phone]/ to augmented_1_dataset/[phone]/images/
2. Keeps labels in augmented_1_dataset/[phone]/labels/ (MATLAB already puts them there)
3. Creates train.txt and val.txt with absolute paths

MATLAB scripts (augment_dataset.m) generate images in phone root + labels in labels/.
This Python script restructures for YOLO: images/ and labels/ as siblings.

Configuration:
    - Train phones: iphone_11, iphone_15, realme_c55
    - Val phone: samsung_a75

Usage:
    python prepare_yolo_dataset.py
"""

import os
import shutil
from pathlib import Path
from typing import List, Tuple
import yaml

# Configuration
PROJECT_ROOT = Path(__file__).parent.parent
AUGMENTED_DATASET = PROJECT_ROOT / "augmented_1_dataset"
PHONE_DIRS = ["iphone_11", "iphone_15", "realme_c55", "samsung_a75"]
VAL_PHONE = "samsung_a75"  # Reserve one phone for validation
TRAIN_PHONES = [p for p in PHONE_DIRS if p != VAL_PHONE]

# Output paths
CONFIGS_DIR = PROJECT_ROOT / "python_scripts" / "configs"
CONFIGS_DIR.mkdir(exist_ok=True)


def restructure_for_yolo() -> int:
    """Restructure dataset to YOLO-compatible format.

    Moves images from phone root to images/ subdirectory if not already there.
    Labels stay in labels/ subdirectory (MATLAB already puts them there).
    Function is idempotent - safe to run multiple times.

    Returns:
        Number of images moved
    """
    total_moved = 0

    for phone in PHONE_DIRS:
        phone_path = AUGMENTED_DATASET / phone
        images_dir = phone_path / "images"

        images_dir.mkdir(exist_ok=True)

        images_in_root = []
        for ext in ["*.jpg", "*.jpeg", "*.png"]:
            for img_path in phone_path.glob(ext):
                if img_path.parent == phone_path:
                    images_in_root.append(img_path)

        if not images_in_root:
            continue

        moved_count = 0
        for img_path in images_in_root:
            dest_path = images_dir / img_path.name
            if not dest_path.exists():
                shutil.move(img_path, dest_path)
                moved_count += 1

        if moved_count > 0:
            print(f"  {phone}: moved {moved_count} images to images/")
            total_moved += moved_count

    return total_moved


def collect_image_paths(phone_dir: str, use_absolute_paths: bool = True) -> List[str]:
    """Collect all image paths from a phone directory.

    Args:
        phone_dir: Phone directory name (e.g., 'iphone_11')
        use_absolute_paths: If True, return absolute paths; if False, return relative paths

    Returns:
        Sorted list of image paths (absolute by default)

    Raises:
        FileNotFoundError: If images/ directory does not exist
        ValueError: If no images found in directory
    """
    phone_path = AUGMENTED_DATASET / phone_dir / "images"

    if not phone_path.exists():
        raise FileNotFoundError(f"Images directory not found: {phone_path}")

    images = []
    for ext in ["*.jpg", "*.jpeg", "*.png"]:
        images.extend(phone_path.glob(ext))

    if not images:
        raise ValueError(f"No images found in {phone_path}")

    if use_absolute_paths:
        images = [str(img.absolute()) for img in images]
    else:
        images = [f"{phone_dir}/images/{img.name}" for img in images]

    return sorted(images)


def create_train_val_txt() -> Tuple[int, int]:
    """Create train.txt and val.txt with image paths."""
    # Collect training images (3 phones)
    train_images = []
    for phone in TRAIN_PHONES:
        train_images.extend(collect_image_paths(phone))

    # Collect validation images (1 phone)
    val_images = collect_image_paths(VAL_PHONE)

    # Write train.txt
    train_txt = AUGMENTED_DATASET / "train.txt"
    with open(train_txt, 'w') as f:
        for img_path in train_images:
            f.write(f"{img_path}\n")

    # Write val.txt
    val_txt = AUGMENTED_DATASET / "val.txt"
    with open(val_txt, 'w') as f:
        for img_path in val_images:
            f.write(f"{img_path}\n")

    print(f"✅ Created {train_txt}")
    print(f"   - Train images: {len(train_images)} (phones: {', '.join(TRAIN_PHONES)})")
    print(f"✅ Created {val_txt}")
    print(f"   - Val images: {len(val_images)} (phone: {VAL_PHONE})")

    return len(train_images), len(val_images)


def create_yolo_config(config_name: str, description: str) -> Path:
    """Create YOLO dataset configuration file."""
    config = {
        'path': AUGMENTED_DATASET.absolute().as_posix(),
        'train': 'train.txt',
        'val': 'val.txt',
        'nc': 1,
        'names': ['concentration_zone']
    }

    config_path = CONFIGS_DIR / f"{config_name}.yaml"
    with open(config_path, 'w') as f:
        f.write(f"# {description}\n")
        f.write(f"# Generated by prepare_yolo_dataset.py\n\n")
        yaml.dump(config, f, default_flow_style=False, sort_keys=False)

    print(f"✅ Created {config_path}")
    return config_path


def print_summary(train_count: int, val_count: int) -> None:
    """Print dataset summary."""
    print("\n" + "="*60)
    print("YOLO Dataset Preparation Complete")
    print("="*60)
    print(f"Dataset path: {AUGMENTED_DATASET}")
    print(f"Train phones: {', '.join(TRAIN_PHONES)}")
    print(f"Val phone: {VAL_PHONE}")
    print(f"Train images: {train_count}")
    print(f"Val images: {val_count}")
    print(f"Total images: {train_count + val_count}")
    print(f"Classes: 1 (concentration_zone)")
    print(f"Config directory: {CONFIGS_DIR}")
    print("="*60)
    print("\nNext steps:")
    print("1. Activate environment: conda activate microPAD-python-env")
    print("2. Train model:")
    print("   python python_scripts/train_yolo.py --stage 1")
    print("   (YOLO scales images to 960x960 at runtime)")
    print("   Or customize resolution:")
    print("   python python_scripts/train_yolo.py --stage 1 --imgsz 960 --batch 24")
    print("="*60)


def verify_labels() -> bool:
    """Verify that label files exist for all images.

    Returns:
        True if all labels exist, False otherwise
    """
    missing_labels = []

    for phone in PHONE_DIRS:
        images = collect_image_paths(phone, use_absolute_paths=True)
        labels_dir = AUGMENTED_DATASET / phone / "labels"

        for img_path in images:
            img_name = Path(img_path).stem
            label_path = labels_dir / f"{img_name}.txt"

            if not label_path.exists():
                missing_labels.append(str(label_path))

    if missing_labels:
        print(f"⚠️  Warning: {len(missing_labels)} label files missing:")
        for label in missing_labels[:5]:
            print(f"   - {label}")
        if len(missing_labels) > 5:
            print(f"   ... and {len(missing_labels) - 5} more")
        return False
    else:
        print(f"✅ All label files verified")
        return True


def main() -> None:
    """Main execution.

    Raises:
        FileNotFoundError: If dataset or phone directories not found
        ValueError: If no images found in directories
    """
    print("="*60)
    print("microPAD YOLO Dataset Preparation")
    print("="*60)

    if not AUGMENTED_DATASET.exists():
        raise FileNotFoundError(f"Dataset not found at {AUGMENTED_DATASET}")

    for phone in PHONE_DIRS:
        phone_path = AUGMENTED_DATASET / phone
        if not phone_path.exists():
            raise FileNotFoundError(f"Phone directory not found: {phone_path}")

    print(f"✅ Dataset found: {AUGMENTED_DATASET}")
    print(f"✅ Phone directories: {', '.join(PHONE_DIRS)}\n")

    print("Restructuring dataset for YOLO...")
    moved_count = restructure_for_yolo()
    if moved_count > 0:
        print(f"✅ Restructured: moved {moved_count} images to images/ subdirectories")
    else:
        print(f"✅ Already restructured: images already in images/ subdirectories")
    print()

    cache_files = list(AUGMENTED_DATASET.glob("*.cache"))
    if cache_files:
        for cache_file in cache_files:
            cache_file.unlink()
        print(f"✅ Deleted {len(cache_files)} cache files")
        print()

    verify_labels()
    print()

    train_count, val_count = create_train_val_txt()
    print()

    create_yolo_config(
        "micropad_synth",
        "microPAD Synthetic Dataset - Train on 3 phones, validate on 1 phone"
    )

    print_summary(train_count, val_count)


if __name__ == "__main__":
    main()
